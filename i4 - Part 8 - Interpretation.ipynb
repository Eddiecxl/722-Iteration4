{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926aacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/23 11:37:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/05/23 11:37:31 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark in Jupyter\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart df\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c10d84c",
   "metadata": {},
   "source": [
    "# Iteration 1 - Adding MIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c5776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df\n",
    "def spark_info(df):\n",
    "    # Get the schema of the DataFrame\n",
    "    schema = df.schema\n",
    "    \n",
    "    # Create a list to hold column information\n",
    "    columns_info = []\n",
    "    \n",
    "    # Iterate through the schema to get column information\n",
    "    for field in schema:\n",
    "        column_name = field.name\n",
    "        column_type = field.dataType.simpleString()\n",
    "        \n",
    "        # Count non-null values\n",
    "        non_null_count = df.filter(col(column_name).isNotNull()).count()\n",
    "        \n",
    "        # Count null values\n",
    "        null_count = df.filter(col(column_name).isNull() | isnan(col(column_name))).count()\n",
    "        \n",
    "        columns_info.append((column_name, column_type, non_null_count, null_count))\n",
    "    \n",
    "    # Display the DataFrame schema and summary\n",
    "    total_rows = df.count()\n",
    "    total_columns = len(schema)\n",
    "    \n",
    "    # Print the summary table\n",
    "    print(f\"DataFrame Summary:\")\n",
    "    print(f\"{'Total Rows':<15}: {total_rows}\")\n",
    "    print(f\"{'Total Columns':<15}: {total_columns}\")\n",
    "    print(\"\\nDataFrame Schema:\")\n",
    "    print(f\"{'Column':<25} {'Non-Null Count':<15} {'Null Count':<10} {'Dtype':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for column_info in columns_info:\n",
    "        print(f\"{column_info[0]:<25} {column_info[2]:<15} {column_info[3]:<10} {column_info[1]:<10}\")\n",
    "\n",
    "# Call the function to describe the DataFrame\n",
    "spark_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc6f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LogisticRegressionClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# We INCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Cognitive_Test_Scores','Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=target, featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions = pipeline_model.transform(train_df)\n",
    "test_predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "test_accuracy = evaluator.evaluate(test_predictions)\n",
    "print(f\"Training Set Accuracy (Evaluator): {train_accuracy}\")\n",
    "print(f\"Testing Set Accuracy (Evaluator): {test_accuracy}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct, train_wrong, train_correct_pct, train_wrong_pct = calculate_correct_wrong(train_predictions, target)\n",
    "test_correct, test_wrong, test_correct_pct, test_wrong_pct = calculate_correct_wrong(test_predictions, target)\n",
    "\n",
    "print(f\"Training Set Correct: {train_correct}\")\n",
    "print(f\"Training Set Wrong: {train_wrong}\")\n",
    "print(f\"Training Set Correct (%): {train_correct_pct}\")\n",
    "print(f\"Training Set Wrong (%): {train_wrong_pct}\")\n",
    "print(f\"Testing Set Correct: {test_correct}\")\n",
    "print(f\"Testing Set Wrong: {test_wrong}\")\n",
    "print(f\"Testing Set Correct (%): {test_correct_pct}\")\n",
    "print(f\"Testing Set Wrong (%): {test_wrong_pct}\")\n",
    "\n",
    "# Define function to plot logistic regression results for both training and testing sets\n",
    "def plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Logistic Regression Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot logistic regression results for both training and testing sets\n",
    "plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                 test_correct, test_correct_pct, test_wrong, test_wrong_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2019cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Logistic Regression Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be64fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DecisionTreeClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# We INCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Cognitive_Test_Scores','Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the DecisionTreeClassifier model\n",
    "dt = DecisionTreeClassifier(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline_dt = Pipeline(stages=indexers + [assembler, dt])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "pipeline_model_dt = pipeline_dt.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_dt = pipeline_model_dt.transform(train_df)\n",
    "test_predictions_dt = pipeline_model_dt.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator_dt = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy_dt = evaluator_dt.evaluate(train_predictions_dt)\n",
    "test_accuracy_dt = evaluator_dt.evaluate(test_predictions_dt)\n",
    "print(f\"Decision Tree - Training Set Accuracy (Evaluator): {train_accuracy_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Accuracy (Evaluator): {test_accuracy_dt}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct_dt, train_wrong_dt, train_correct_pct_dt, train_wrong_pct_dt = calculate_correct_wrong(train_predictions_dt, target)\n",
    "test_correct_dt, test_wrong_dt, test_correct_pct_dt, test_wrong_pct_dt = calculate_correct_wrong(test_predictions_dt, target)\n",
    "\n",
    "print(f\"Decision Tree - Training Set Correct: {train_correct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong: {train_wrong_dt}\")\n",
    "print(f\"Decision Tree - Training Set Correct (%): {train_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong (%): {train_wrong_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct: {test_correct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong: {test_wrong_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct (%): {test_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong (%): {test_wrong_pct_dt}\")\n",
    "\n",
    "# Define function to plot decision tree results for both training and testing sets\n",
    "def plot_decision_tree_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                               test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Decision Tree Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision tree results for both training and testing sets\n",
    "plot_decision_tree_results(train_correct_dt, train_correct_pct_dt, train_wrong_dt, train_wrong_pct_dt,\n",
    "                           test_correct_dt, test_correct_pct_dt, test_wrong_dt, test_wrong_pct_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee715e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Decision Tree Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy_dt, test_accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f403eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline as SparkPipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Assuming 'Education_Group' is a categorical feature causing the issue\n",
    "#categorical_features = ['Dementia']\n",
    "categorical_features = ['Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Create a column transformer to apply different preprocessing steps to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame for sklearn\n",
    "X_train = train_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_train = train_df.select(target).toPandas()\n",
    "\n",
    "X_test = test_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_test = test_df.select(target).toPandas()\n",
    "\n",
    "# Create a pipeline with preprocessing and KNN classifier\n",
    "pipeline_knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_knn = pipeline_knn.predict(X_train)\n",
    "test_predictions_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy using sklearn for both training and testing sets\n",
    "train_accuracy_sklearn_knn = accuracy_score(y_train, train_predictions_knn)\n",
    "test_accuracy_sklearn_knn = accuracy_score(y_test, test_predictions_knn)\n",
    "print(\"KNN - Training Set Accuracy:\", train_accuracy_sklearn_knn)\n",
    "print(\"KNN - Testing Set Accuracy:\", test_accuracy_sklearn_knn)\n",
    "\n",
    "# Calculate confusion matrix using sklearn for both training and testing sets\n",
    "train_cm_knn = confusion_matrix(y_train, train_predictions_knn)\n",
    "test_cm_knn = confusion_matrix(y_test, test_predictions_knn)\n",
    "\n",
    "# Calculate number of correct and wrong predictions for both training and testing sets\n",
    "train_correct_knn = train_cm_knn[0, 0] + train_cm_knn[1, 1]\n",
    "train_wrong_knn = train_cm_knn[0, 1] + train_cm_knn[1, 0]\n",
    "test_correct_knn = test_cm_knn[0, 0] + test_cm_knn[1, 1]\n",
    "test_wrong_knn = test_cm_knn[0, 1] + test_cm_knn[1, 0]\n",
    "\n",
    "# Calculate percentages of correct and wrong predictions for both training and testing sets\n",
    "train_total_knn = len(y_train)\n",
    "test_total_knn = len(y_test)\n",
    "train_correct_pct_knn = (train_correct_knn / train_total_knn) * 100\n",
    "train_wrong_pct_knn = (train_wrong_knn / train_total_knn) * 100\n",
    "test_correct_pct_knn = (test_correct_knn / test_total_knn) * 100\n",
    "test_wrong_pct_knn = (test_wrong_knn / test_total_knn) * 100\n",
    "\n",
    "# Define function to plot KNN results for both training and testing sets\n",
    "def plot_knn_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('KNN Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot KNN results for both training and testing sets\n",
    "plot_knn_results(train_correct_knn, train_correct_pct_knn, train_wrong_knn, train_wrong_pct_knn,\n",
    "                 test_correct_knn, test_correct_pct_knn, test_wrong_knn, test_wrong_pct_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_knn(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('KNN Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy_knn(train_accuracy_sklearn_knn, test_accuracy_sklearn_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d887914e",
   "metadata": {},
   "source": [
    "# Iteration 2 - Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf1fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart df\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8db94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample the DataFrame to boost it\n",
    "boosted_df = df.sample(withReplacement=True, fraction=2.0, seed=42)\n",
    "\n",
    "# Count the total number of rows in the boosted DataFrame\n",
    "total_rows = boosted_df.count()\n",
    "print(\"Total rows in the boosted DataFrame:\", total_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd188a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df\n",
    "def spark_info(boosted_df):\n",
    "    # Get the schema of the DataFrame\n",
    "    schema = df.schema\n",
    "    \n",
    "    # Create a list to hold column information\n",
    "    columns_info = []\n",
    "    \n",
    "    # Iterate through the schema to get column information\n",
    "    for field in schema:\n",
    "        column_name = field.name\n",
    "        column_type = field.dataType.simpleString()\n",
    "        \n",
    "        # Count non-null values\n",
    "        non_null_count = boosted_df.filter(col(column_name).isNotNull()).count()\n",
    "        \n",
    "        # Count null values\n",
    "        null_count = boosted_df.filter(col(column_name).isNull() | isnan(col(column_name))).count()\n",
    "        \n",
    "        columns_info.append((column_name, column_type, non_null_count, null_count))\n",
    "    \n",
    "    # Display the DataFrame schema and summary\n",
    "    total_rows = boosted_df.count()\n",
    "    total_columns = len(schema)\n",
    "    \n",
    "    # Print the summary table\n",
    "    print(f\"DataFrame Summary:\")\n",
    "    print(f\"{'Total Rows':<15}: {total_rows}\")\n",
    "    print(f\"{'Total Columns':<15}: {total_columns}\")\n",
    "    print(\"\\nDataFrame Schema:\")\n",
    "    print(f\"{'Column':<25} {'Non-Null Count':<15} {'Null Count':<10} {'Dtype':<10}\")\n",
    "    print(\"-\" * 60)\n",
    "    for column_info in columns_info:\n",
    "        print(f\"{column_info[0]:<25} {column_info[2]:<15} {column_info[3]:<10} {column_info[1]:<10}\")\n",
    "\n",
    "# Call the function to describe the DataFrame\n",
    "spark_info(boosted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f4134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LogisticRegressionClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Randomly sample the DataFrame to boost it\n",
    "df = df.sample(withReplacement=True, fraction=2.0, seed=42)\n",
    "\n",
    "# Count the total number of rows in the boosted DataFrame\n",
    "total_rows = df.count()\n",
    "print(\"Total rows in the boosted DataFrame:\", total_rows)\n",
    "\n",
    "# We INCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Cognitive_Test_Scores','Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=target, featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions = pipeline_model.transform(train_df)\n",
    "test_predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "test_accuracy = evaluator.evaluate(test_predictions)\n",
    "print(f\"Training Set Accuracy (Evaluator): {train_accuracy}\")\n",
    "print(f\"Testing Set Accuracy (Evaluator): {test_accuracy}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct, train_wrong, train_correct_pct, train_wrong_pct = calculate_correct_wrong(train_predictions, target)\n",
    "test_correct, test_wrong, test_correct_pct, test_wrong_pct = calculate_correct_wrong(test_predictions, target)\n",
    "\n",
    "print(f\"Training Set Correct: {train_correct}\")\n",
    "print(f\"Training Set Wrong: {train_wrong}\")\n",
    "print(f\"Training Set Correct (%): {train_correct_pct}\")\n",
    "print(f\"Training Set Wrong (%): {train_wrong_pct}\")\n",
    "print(f\"Testing Set Correct: {test_correct}\")\n",
    "print(f\"Testing Set Wrong: {test_wrong}\")\n",
    "print(f\"Testing Set Correct (%): {test_correct_pct}\")\n",
    "print(f\"Testing Set Wrong (%): {test_wrong_pct}\")\n",
    "\n",
    "# Define function to plot logistic regression results for both training and testing sets\n",
    "def plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Logistic Regression Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot logistic regression results for both training and testing sets\n",
    "plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                 test_correct, test_correct_pct, test_wrong, test_wrong_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Logistic Regression Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81574c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DecisionTreeClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Randomly sample the DataFrame to boost it\n",
    "df = df.sample(withReplacement=True, fraction=2.0, seed=42)\n",
    "\n",
    "# Count the total number of rows in the boosted DataFrame\n",
    "total_rows = df.count()\n",
    "print(\"Total rows in the boosted DataFrame:\", total_rows)\n",
    "\n",
    "# We INCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Cognitive_Test_Scores','Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the DecisionTreeClassifier model\n",
    "dt = DecisionTreeClassifier(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline_dt = Pipeline(stages=indexers + [assembler, dt])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "pipeline_model_dt = pipeline_dt.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_dt = pipeline_model_dt.transform(train_df)\n",
    "test_predictions_dt = pipeline_model_dt.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator_dt = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy_dt = evaluator_dt.evaluate(train_predictions_dt)\n",
    "test_accuracy_dt = evaluator_dt.evaluate(test_predictions_dt)\n",
    "print(f\"Decision Tree - Training Set Accuracy (Evaluator): {train_accuracy_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Accuracy (Evaluator): {test_accuracy_dt}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct_dt, train_wrong_dt, train_correct_pct_dt, train_wrong_pct_dt = calculate_correct_wrong(train_predictions_dt, target)\n",
    "test_correct_dt, test_wrong_dt, test_correct_pct_dt, test_wrong_pct_dt = calculate_correct_wrong(test_predictions_dt, target)\n",
    "\n",
    "print(f\"Decision Tree - Training Set Correct: {train_correct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong: {train_wrong_dt}\")\n",
    "print(f\"Decision Tree - Training Set Correct (%): {train_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong (%): {train_wrong_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct: {test_correct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong: {test_wrong_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct (%): {test_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong (%): {test_wrong_pct_dt}\")\n",
    "\n",
    "# Define function to plot decision tree results for both training and testing sets\n",
    "def plot_decision_tree_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                               test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Decision Tree Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision tree results for both training and testing sets\n",
    "plot_decision_tree_results(train_correct_dt, train_correct_pct_dt, train_wrong_dt, train_wrong_pct_dt,\n",
    "                           test_correct_dt, test_correct_pct_dt, test_wrong_dt, test_wrong_pct_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60402c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Decision Tree Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy_dt, test_accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d87496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline as SparkPipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Assuming 'Education_Group' is a categorical feature causing the issue\n",
    "#categorical_features = ['Dementia']\n",
    "categorical_features = ['Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Create a column transformer to apply different preprocessing steps to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame for sklearn\n",
    "X_train = train_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_train = train_df.select(target).toPandas()\n",
    "\n",
    "X_test = test_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_test = test_df.select(target).toPandas()\n",
    "\n",
    "# Create a pipeline with preprocessing and KNN classifier\n",
    "pipeline_knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_knn = pipeline_knn.predict(X_train)\n",
    "test_predictions_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy using sklearn for both training and testing sets\n",
    "train_accuracy_sklearn_knn = accuracy_score(y_train, train_predictions_knn)\n",
    "test_accuracy_sklearn_knn = accuracy_score(y_test, test_predictions_knn)\n",
    "print(\"KNN - Training Set Accuracy:\", train_accuracy_sklearn_knn)\n",
    "print(\"KNN - Testing Set Accuracy:\", test_accuracy_sklearn_knn)\n",
    "\n",
    "# Calculate confusion matrix using sklearn for both training and testing sets\n",
    "train_cm_knn = confusion_matrix(y_train, train_predictions_knn)\n",
    "test_cm_knn = confusion_matrix(y_test, test_predictions_knn)\n",
    "\n",
    "# Calculate number of correct and wrong predictions for both training and testing sets\n",
    "train_correct_knn = train_cm_knn[0, 0] + train_cm_knn[1, 1]\n",
    "train_wrong_knn = train_cm_knn[0, 1] + train_cm_knn[1, 0]\n",
    "test_correct_knn = test_cm_knn[0, 0] + test_cm_knn[1, 1]\n",
    "test_wrong_knn = test_cm_knn[0, 1] + test_cm_knn[1, 0]\n",
    "\n",
    "# Calculate percentages of correct and wrong predictions for both training and testing sets\n",
    "train_total_knn = len(y_train)\n",
    "test_total_knn = len(y_test)\n",
    "train_correct_pct_knn = (train_correct_knn / train_total_knn) * 100\n",
    "train_wrong_pct_knn = (train_wrong_knn / train_total_knn) * 100\n",
    "test_correct_pct_knn = (test_correct_knn / test_total_knn) * 100\n",
    "test_wrong_pct_knn = (test_wrong_knn / test_total_knn) * 100\n",
    "\n",
    "# Define function to plot KNN results for both training and testing sets\n",
    "def plot_knn_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('KNN Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot KNN results for both training and testing sets\n",
    "plot_knn_results(train_correct_knn, train_correct_pct_knn, train_wrong_knn, train_wrong_pct_knn,\n",
    "                 test_correct_knn, test_correct_pct_knn, test_wrong_knn, test_wrong_pct_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_knn(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('KNN Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy_knn(train_accuracy_sklearn_knn, test_accuracy_sklearn_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e194e",
   "metadata": {},
   "source": [
    "# Iteration 3 - Remove MIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"LogisticRegressionClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Randomly sample the DataFrame to boost it\n",
    "df = df.sample(withReplacement=True, fraction=2.0, seed=42)\n",
    "\n",
    "# Count the total number of rows in the boosted DataFrame\n",
    "total_rows = df.count()\n",
    "print(\"Total rows in the boosted DataFrame:\", total_rows)\n",
    "\n",
    "# We EXCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=target, featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, lr])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions = pipeline_model.transform(train_df)\n",
    "test_predictions = pipeline_model.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy = evaluator.evaluate(train_predictions)\n",
    "test_accuracy = evaluator.evaluate(test_predictions)\n",
    "print(f\"Training Set Accuracy (Evaluator): {train_accuracy}\")\n",
    "print(f\"Testing Set Accuracy (Evaluator): {test_accuracy}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct, train_wrong, train_correct_pct, train_wrong_pct = calculate_correct_wrong(train_predictions, target)\n",
    "test_correct, test_wrong, test_correct_pct, test_wrong_pct = calculate_correct_wrong(test_predictions, target)\n",
    "\n",
    "print(f\"Training Set Correct: {train_correct}\")\n",
    "print(f\"Training Set Wrong: {train_wrong}\")\n",
    "print(f\"Training Set Correct (%): {train_correct_pct}\")\n",
    "print(f\"Training Set Wrong (%): {train_wrong_pct}\")\n",
    "print(f\"Testing Set Correct: {test_correct}\")\n",
    "print(f\"Testing Set Wrong: {test_wrong}\")\n",
    "print(f\"Testing Set Correct (%): {test_correct_pct}\")\n",
    "print(f\"Testing Set Wrong (%): {test_wrong_pct}\")\n",
    "\n",
    "# Define function to plot logistic regression results for both training and testing sets\n",
    "def plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Logistic Regression Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot logistic regression results for both training and testing sets\n",
    "plot_logistic_regression_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                                 test_correct, test_correct_pct, test_wrong, test_wrong_pct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Logistic Regression Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy, test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d95b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DecisionTreeClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.csv('Dataset/df_new_6d.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Randomly sample the DataFrame to boost it\n",
    "df = df.sample(withReplacement=True, fraction=2.0, seed=42)\n",
    "\n",
    "# Count the total number of rows in the boosted DataFrame\n",
    "total_rows = df.count()\n",
    "print(\"Total rows in the boosted DataFrame:\", total_rows)\n",
    "\n",
    "# We EXCLUDE Cognitive Test Scores\n",
    "# Select all features and the target variable\n",
    "categorical_features = ['Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "numeric_features = ['Age', 'AlcoholLevel', 'HeartRate', 'BodyTemperature', 'Weight', 'MRI_Delay']\n",
    "target = 'Dementia'\n",
    "\n",
    "# Index categorical features\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_index\") for column in categorical_features]\n",
    "\n",
    "# Assemble features into a feature vector\n",
    "assembler = VectorAssembler(inputCols=[column + \"_index\" for column in categorical_features] + numeric_features, outputCol=\"features\")\n",
    "\n",
    "# Initialize the DecisionTreeClassifier model\n",
    "dt = DecisionTreeClassifier(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "# Create a Pipeline\n",
    "pipeline_dt = Pipeline(stages=indexers + [assembler, dt])\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the Decision Tree model\n",
    "pipeline_model_dt = pipeline_dt.fit(train_df)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_dt = pipeline_model_dt.transform(train_df)\n",
    "test_predictions_dt = pipeline_model_dt.transform(test_df)\n",
    "\n",
    "# Evaluate the Model for both training and testing sets using accuracy metric\n",
    "evaluator_dt = MulticlassClassificationEvaluator(labelCol=target, metricName=\"accuracy\")\n",
    "train_accuracy_dt = evaluator_dt.evaluate(train_predictions_dt)\n",
    "test_accuracy_dt = evaluator_dt.evaluate(test_predictions_dt)\n",
    "print(f\"Decision Tree - Training Set Accuracy (Evaluator): {train_accuracy_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Accuracy (Evaluator): {test_accuracy_dt}\")\n",
    "\n",
    "# Calculate correct and incorrect predictions\n",
    "def calculate_correct_wrong(predictions, label_col):\n",
    "    pred_labels = predictions.select('prediction', label_col).rdd\n",
    "    pred_labels = pred_labels.map(lambda row: (row['prediction'], row[label_col]))\n",
    "    \n",
    "    tp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 1.0).count()\n",
    "    tn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 0.0).count()\n",
    "    fp = pred_labels.filter(lambda pl: pl[0] == 1.0 and pl[1] == 0.0).count()\n",
    "    fn = pred_labels.filter(lambda pl: pl[0] == 0.0 and pl[1] == 1.0).count()\n",
    "    \n",
    "    correct = tp + tn\n",
    "    wrong = fp + fn\n",
    "    \n",
    "    total = correct + wrong\n",
    "    correct_pct = (correct / total) * 100\n",
    "    wrong_pct = (wrong / total) * 100\n",
    "    \n",
    "    return correct, wrong, correct_pct, wrong_pct\n",
    "\n",
    "train_correct_dt, train_wrong_dt, train_correct_pct_dt, train_wrong_pct_dt = calculate_correct_wrong(train_predictions_dt, target)\n",
    "test_correct_dt, test_wrong_dt, test_correct_pct_dt, test_wrong_pct_dt = calculate_correct_wrong(test_predictions_dt, target)\n",
    "\n",
    "print(f\"Decision Tree - Training Set Correct: {train_correct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong: {train_wrong_dt}\")\n",
    "print(f\"Decision Tree - Training Set Correct (%): {train_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Training Set Wrong (%): {train_wrong_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct: {test_correct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong: {test_wrong_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Correct (%): {test_correct_pct_dt}\")\n",
    "print(f\"Decision Tree - Testing Set Wrong (%): {test_wrong_pct_dt}\")\n",
    "\n",
    "# Define function to plot decision tree results for both training and testing sets\n",
    "def plot_decision_tree_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                               test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('Decision Tree Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision tree results for both training and testing sets\n",
    "plot_decision_tree_results(train_correct_dt, train_correct_pct_dt, train_wrong_dt, train_wrong_pct_dt,\n",
    "                           test_correct_dt, test_correct_pct_dt, test_wrong_dt, test_wrong_pct_dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Decision Tree Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy(train_accuracy_dt, test_accuracy_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf501d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline as SparkPipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Assuming 'Education_Group' is a categorical feature causing the issue\n",
    "#categorical_features = ['Dementia']\n",
    "categorical_features = ['Family_History', 'Smoking_Status', 'APOE_ε4', 'Depression_Status', 'Education_Group']\n",
    "\n",
    "# Define preprocessing steps for numerical and categorical features\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Create a column transformer to apply different preprocessing steps to different columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame for sklearn\n",
    "X_train = train_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_train = train_df.select(target).toPandas()\n",
    "\n",
    "X_test = test_df.select(*numeric_features, *categorical_features).toPandas()\n",
    "y_test = test_df.select(target).toPandas()\n",
    "\n",
    "# Create a pipeline with preprocessing and KNN classifier\n",
    "pipeline_knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on both the training and testing data\n",
    "train_predictions_knn = pipeline_knn.predict(X_train)\n",
    "test_predictions_knn = pipeline_knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy using sklearn for both training and testing sets\n",
    "train_accuracy_sklearn_knn = accuracy_score(y_train, train_predictions_knn)\n",
    "test_accuracy_sklearn_knn = accuracy_score(y_test, test_predictions_knn)\n",
    "print(\"KNN - Training Set Accuracy:\", train_accuracy_sklearn_knn)\n",
    "print(\"KNN - Testing Set Accuracy:\", test_accuracy_sklearn_knn)\n",
    "\n",
    "# Calculate confusion matrix using sklearn for both training and testing sets\n",
    "train_cm_knn = confusion_matrix(y_train, train_predictions_knn)\n",
    "test_cm_knn = confusion_matrix(y_test, test_predictions_knn)\n",
    "\n",
    "# Calculate number of correct and wrong predictions for both training and testing sets\n",
    "train_correct_knn = train_cm_knn[0, 0] + train_cm_knn[1, 1]\n",
    "train_wrong_knn = train_cm_knn[0, 1] + train_cm_knn[1, 0]\n",
    "test_correct_knn = test_cm_knn[0, 0] + test_cm_knn[1, 1]\n",
    "test_wrong_knn = test_cm_knn[0, 1] + test_cm_knn[1, 0]\n",
    "\n",
    "# Calculate percentages of correct and wrong predictions for both training and testing sets\n",
    "train_total_knn = len(y_train)\n",
    "test_total_knn = len(y_test)\n",
    "train_correct_pct_knn = (train_correct_knn / train_total_knn) * 100\n",
    "train_wrong_pct_knn = (train_wrong_knn / train_total_knn) * 100\n",
    "test_correct_pct_knn = (test_correct_knn / test_total_knn) * 100\n",
    "test_wrong_pct_knn = (test_wrong_knn / test_total_knn) * 100\n",
    "\n",
    "# Define function to plot KNN results for both training and testing sets\n",
    "def plot_knn_results(train_correct, train_correct_pct, train_wrong, train_wrong_pct,\n",
    "                     test_correct, test_correct_pct, test_wrong, test_wrong_pct):\n",
    "    labels = ['Training Set', 'Testing Set']\n",
    "    correct = [train_correct, test_correct]\n",
    "    correct_pct = [round(train_correct_pct, 2), round(test_correct_pct, 2)]\n",
    "    wrong = [train_wrong, test_wrong]\n",
    "    wrong_pct = [round(train_wrong_pct, 2), round(test_wrong_pct, 2)]\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects1 = ax.bar(x - width, correct, width, label='Correct', color='lightgreen')\n",
    "    rects2 = ax.bar(x, wrong, width, label='Wrong', color='salmon')\n",
    "    rects3 = ax.bar(x + width, correct_pct, width, label='Correct (%)', color='skyblue')\n",
    "    rects4 = ax.bar(x + 2*width, wrong_pct, width, label='Wrong (%)', color='orange')\n",
    "    ax.set_ylabel('Count / Percentage')\n",
    "    ax.set_title('KNN Model Performance Comparison')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend(loc='center')\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  \n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    autolabel(rects3)\n",
    "    autolabel(rects4)\n",
    "    plt.show()\n",
    "\n",
    "# Plot KNN results for both training and testing sets\n",
    "plot_knn_results(train_correct_knn, train_correct_pct_knn, train_wrong_knn, train_wrong_pct_knn,\n",
    "                 test_correct_knn, test_correct_pct_knn, test_wrong_knn, test_wrong_pct_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b213b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_accuracy_knn(train_accuracy, test_accuracy):\n",
    "    # Generate x values for interpolation\n",
    "    x_values = np.linspace(0, 1, num=100)\n",
    "    \n",
    "    # Interpolate between the two accuracy points\n",
    "    train_line = np.linspace(0, train_accuracy, num=100)\n",
    "    test_line = np.linspace(0, test_accuracy, num=100)\n",
    "    \n",
    "    # Plot training set accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_values, train_line, label='Training Set Accuracy')\n",
    "    plt.plot(x_values, test_line, label='Testing Set Accuracy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='red', label='Perfect Accuracy')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('KNN Model Evaluation')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot accuracy for both training and testing sets\n",
    "plot_accuracy_knn(train_accuracy_sklearn_knn, test_accuracy_sklearn_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
